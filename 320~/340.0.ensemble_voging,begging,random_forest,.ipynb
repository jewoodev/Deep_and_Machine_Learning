{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블(Ensemble) - 1. 보팅, 배깅, 랜덤포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보팅( Voting Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 분류기의 성능과 보팅 분류기의 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하드보팅 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# 위스콘식 유방암 데이터세트\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "b_cancer = load_breast_cancer()\n",
    "b_cancer.keys()\n",
    "print(b_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 살펴보기\n",
    "b_cancer = load_breast_cancer()\n",
    "data_df = pd.DataFrame(b_cancer.data, columns=b_cancer.feature_names)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = b_cancer.data\n",
    "y = b_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\\\n",
    "    random_state=156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 로지스틱 회귀, KNN을 기반으로 한 소프트보팅 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758241758241758\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 서로 다른 개별 학습기 생성\n",
    "lr_clf = LogisticRegression(max_iter=100000)\n",
    "knn_Clf = KNeighborsClassifier(n_neighbors=8)\n",
    "dt_clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# 앙상블 학습기 생성\n",
    "voting_clf = VotingClassifier([('LR', lr_clf), ('KNN', knn_Clf), ('DT', dt_clf)],\\\n",
    "    voting='soft')\n",
    "# 앙상블 학습기 학습\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "train_score = accuracy_score(y_train, voting_clf.predict(X_train))\n",
    "test_score = accuracy_score(y_test, voting_clf.predict(X_test))\n",
    "\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train score : 0.9582417582417583\n",
      "LogisticRegression test score : 0.9649122807017544\n",
      "KNeighborsClassifier train score : 0.9384615384615385\n",
      "KNeighborsClassifier test score : 0.9385964912280702\n",
      "DecisionTreeClassifier train score : 0.9736263736263736\n",
      "DecisionTreeClassifier test score : 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# 앙상블하지 않은 각각의 학습기의 성능을 측정하시오.\n",
    "lr_clf.fit(X_train, y_train)\n",
    "train_score = accuracy_score(y_train, lr_clf.predict(X_train))\n",
    "test_score = accuracy_score(y_test, lr_clf.predict(X_test))\n",
    "print(f'LogisticRegression train score : {train_score}')\n",
    "print(f'LogisticRegression test score : {test_score}')\n",
    "knn_Clf.fit(X_train, y_train)\n",
    "train_score = accuracy_score(y_train, knn_Clf.predict(X_train))\n",
    "test_score = accuracy_score(y_test, knn_Clf.predict(X_test))\n",
    "print(f'KNeighborsClassifier train score : {train_score}')\n",
    "print(f'KNeighborsClassifier test score : {test_score}')\n",
    "dt_clf.fit(X_train, y_train)\n",
    "train_score = accuracy_score(y_train, dt_clf.predict(X_train))\n",
    "test_score = accuracy_score(y_test, dt_clf.predict(X_test))\n",
    "print(f'DecisionTreeClassifier train score : {train_score}')\n",
    "print(f'DecisionTreeClassifier test score : {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest : 와인 데이터셋"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 파라미터  \n",
    "n_estimators: 모형(week learner)의 개수, 순차적으로 오류를 보정해 수가 많으면 성능이 일정 수준까지 높아질 수 있으나, 수행 시간이 오래 걸린다는 단점이 있음(디폴트는 100)  \n",
    "min_samples_leaf: 말단 리프 노드의 최소한의 샘플 데이터 수, 디폴트 1  \n",
    "max_depth: 트리의 최대 깊이, 디폴트 3  \n",
    "max_features: 디폴트는 auto, If “auto”, then max_features=sqrt(n_features) 즉, 피처가 4개면 분할을 위해 2개 참조   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_kaggle = pd.read_csv('data/wine_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PlayData\\AppData\\Local\\Temp\\ipykernel_7928\\566352816.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wine['style'] = wine['style'].replace('red', 0)\n",
      "C:\\Users\\PlayData\\AppData\\Local\\Temp\\ipykernel_7928\\566352816.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wine['style'] = wine['style'].replace('white', 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할 :test_size=0.2, random_state=42\n",
    "\n",
    "wine = wine_kaggle[['alcohol', 'residual_sugar', 'pH', 'style']]\n",
    "wine.columns = ['alcohol', 'sugar', 'pH', 'style']\n",
    "wine['style'] = wine['style'].replace('red', 0)\n",
    "wine['style'] = wine['style'].replace('white', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= wine.iloc[:, :-1]\n",
    "y = wine.iloc[:, -1]\n",
    "\n",
    "# 분할 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\\\n",
    "    y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996921300750433\n",
      "0.8892307692307693\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier 모델 구축, 학습 및 평가\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train))\n",
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test))\n",
    "\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7928\\1062088380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    820\u001b[0m                     )\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    823\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PlayData\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 과대적합이므로 그리드서치\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [100, 200, 300, 400, 500], \n",
    "    'max_depth' : [3, 5, 7, 9, 11],\n",
    "    'min_samples_leaf' : [8, 12 ,18],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "grid = GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'min_samples_leaf': 8,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=9, min_samples_leaf=8, min_samples_split=8,\n",
       "                       n_estimators=500, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=9, min_samples_leaf=8, min_samples_split=8,\n",
       "                       n_estimators=500, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=9, min_samples_leaf=8, min_samples_split=8,\n",
       "                       n_estimators=500, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = grid.best_estimator_ # 베스트 모델\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8964787377333077\n",
      "0.8638461538461538\n"
     ]
    }
   ],
   "source": [
    "train_score = accuracy_score(y_train, best.predict(X_train))\n",
    "test_score = accuracy_score(y_test, best.predict(X_test))\n",
    "\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [참고] 트리 갯수 300개로 증가시킨후 학습 -> 별도의 테스트 데이터셋에서 예측 -> 성능측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 중요도(feature importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16107679, 0.61928965, 0.21963356])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_imp = pd.Series(data=best.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.barplot(x=f_imp.values, y=f_imp.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습]  사용자 행동 인식 데이터 세트 랜덤포레스트 분류하라\n",
    "(기본 모델 -> 하이퍼파라미터 튜닝 -> 피처 중요도 시각화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처별 중요도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습] 타이타닉 데이터셋 랜덤 포레스트 분류\n",
    "기본 모델 - 하이퍼파라미터 튜닝 - 특성 중요도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic/df_titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.266662</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.070022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.972177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.085672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.622855</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.050913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.690430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Survived   Age  SibSp  Parch      Fare  Pclass_2  Pclass_3  Sex_1\n",
       "0            0  22.0      1      0  1.981001         0         1      1\n",
       "1            1  38.0      1      0  4.266662         0         0      0\n",
       "2            1  26.0      0      0  2.070022         0         1      0\n",
       "3            1  35.0      1      0  3.972177         0         0      0\n",
       "4            0  35.0      0      0  2.085672         0         1      1\n",
       "...        ...   ...    ...    ...       ...       ...       ...    ...\n",
       "1038         1   3.0      1      1  2.622855         0         1      0\n",
       "1039         1  37.0      1      0  4.499810         0         0      0\n",
       "1040         1  28.0      0      0  2.050913         0         1      0\n",
       "1041         1  39.0      0      0  4.690430         0         0      0\n",
       "1042         0  38.5      0      0  1.981001         0         1      1\n",
       "\n",
       "[1043 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='Survived')\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8633093525179856\n",
      "0.9043062200956937\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_train, dt_clf.predict(X_train)))\n",
    "print(accuracy_score(y_test, dt_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "A random forest classifier.\n",
      "\n",
      "A random forest is a meta estimator that fits a number of decision tree\n",
      "classifiers on various sub-samples of the dataset and uses averaging to\n",
      "improve the predictive accuracy and control over-fitting.\n",
      "The sub-sample size is controlled with the `max_samples` parameter if\n",
      "`bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      "each tree.\n",
      "\n",
      "Read more in the :ref:`User Guide <forest>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_estimators : int, default=100\n",
      "    The number of trees in the forest.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "       The default value of ``n_estimators`` changed from 10 to 100\n",
      "       in 0.22.\n",
      "\n",
      "criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
      "    The function to measure the quality of a split. Supported criteria are\n",
      "    \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
      "    Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
      "    Note: This parameter is tree-specific.\n",
      "\n",
      "max_depth : int, default=None\n",
      "    The maximum depth of the tree. If None, then nodes are expanded until\n",
      "    all leaves are pure or until all leaves contain less than\n",
      "    min_samples_split samples.\n",
      "\n",
      "min_samples_split : int or float, default=2\n",
      "    The minimum number of samples required to split an internal node:\n",
      "\n",
      "    - If int, then consider `min_samples_split` as the minimum number.\n",
      "    - If float, then `min_samples_split` is a fraction and\n",
      "      `ceil(min_samples_split * n_samples)` are the minimum\n",
      "      number of samples for each split.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_samples_leaf : int or float, default=1\n",
      "    The minimum number of samples required to be at a leaf node.\n",
      "    A split point at any depth will only be considered if it leaves at\n",
      "    least ``min_samples_leaf`` training samples in each of the left and\n",
      "    right branches.  This may have the effect of smoothing the model,\n",
      "    especially in regression.\n",
      "\n",
      "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "    - If float, then `min_samples_leaf` is a fraction and\n",
      "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "      number of samples for each node.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_weight_fraction_leaf : float, default=0.0\n",
      "    The minimum weighted fraction of the sum total of weights (of all\n",
      "    the input samples) required to be at a leaf node. Samples have\n",
      "    equal weight when sample_weight is not provided.\n",
      "\n",
      "max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n",
      "    The number of features to consider when looking for the best split:\n",
      "\n",
      "    - If int, then consider `max_features` features at each split.\n",
      "    - If float, then `max_features` is a fraction and\n",
      "      `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      "      split.\n",
      "    - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      "    - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "    - If \"log2\", then `max_features=log2(n_features)`.\n",
      "    - If None, then `max_features=n_features`.\n",
      "\n",
      "    .. versionchanged:: 1.1\n",
      "        The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n",
      "\n",
      "    .. deprecated:: 1.1\n",
      "        The `\"auto\"` option was deprecated in 1.1 and will be removed\n",
      "        in 1.3.\n",
      "\n",
      "    Note: the search for a split does not stop until at least one\n",
      "    valid partition of the node samples is found, even if it requires to\n",
      "    effectively inspect more than ``max_features`` features.\n",
      "\n",
      "max_leaf_nodes : int, default=None\n",
      "    Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      "    Best nodes are defined as relative reduction in impurity.\n",
      "    If None then unlimited number of leaf nodes.\n",
      "\n",
      "min_impurity_decrease : float, default=0.0\n",
      "    A node will be split if this split induces a decrease of the impurity\n",
      "    greater than or equal to this value.\n",
      "\n",
      "    The weighted impurity decrease equation is the following::\n",
      "\n",
      "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                            - N_t_L / N_t * left_impurity)\n",
      "\n",
      "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "    if ``sample_weight`` is passed.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "\n",
      "bootstrap : bool, default=True\n",
      "    Whether bootstrap samples are used when building trees. If False, the\n",
      "    whole dataset is used to build each tree.\n",
      "\n",
      "oob_score : bool, default=False\n",
      "    Whether to use out-of-bag samples to estimate the generalization score.\n",
      "    Only available if bootstrap=True.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      "    :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      "    trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      "    context. ``-1`` means using all processors. See :term:`Glossary\n",
      "    <n_jobs>` for more details.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Controls both the randomness of the bootstrapping of the samples used\n",
      "    when building trees (if ``bootstrap=True``) and the sampling of the\n",
      "    features to consider when looking for the best split at each node\n",
      "    (if ``max_features < n_features``).\n",
      "    See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "verbose : int, default=0\n",
      "    Controls the verbosity when fitting and predicting.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to ``True``, reuse the solution of the previous call to fit\n",
      "    and add more estimators to the ensemble, otherwise, just fit a whole\n",
      "    new forest. See :term:`Glossary <warm_start>` and\n",
      "    :ref:`gradient_boosting_warm_start` for details.\n",
      "\n",
      "class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      "    Weights associated with classes in the form ``{class_label: weight}``.\n",
      "    If not given, all classes are supposed to have weight one. For\n",
      "    multi-output problems, a list of dicts can be provided in the same\n",
      "    order as the columns of y.\n",
      "\n",
      "    Note that for multioutput (including multilabel) weights should be\n",
      "    defined for each class of every column in its own dict. For example,\n",
      "    for four-class multilabel classification weights should be\n",
      "    [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "    [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "    The \"balanced\" mode uses the values of y to automatically adjust\n",
      "    weights inversely proportional to class frequencies in the input data\n",
      "    as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "    The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      "    weights are computed based on the bootstrap sample for every tree\n",
      "    grown.\n",
      "\n",
      "    For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "    Note that these weights will be multiplied with sample_weight (passed\n",
      "    through the fit method) if sample_weight is specified.\n",
      "\n",
      "ccp_alpha : non-negative float, default=0.0\n",
      "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "    subtree with the largest cost complexity that is smaller than\n",
      "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "    :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "max_samples : int or float, default=None\n",
      "    If bootstrap is True, the number of samples to draw from X\n",
      "    to train each base estimator.\n",
      "\n",
      "    - If None (default), then draw `X.shape[0]` samples.\n",
      "    - If int, then draw `max_samples` samples.\n",
      "    - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      "      `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\n",
      "    The child estimator template used to create the collection of fitted\n",
      "    sub-estimators.\n",
      "\n",
      "    .. versionadded:: 1.2\n",
      "       `base_estimator_` was renamed to `estimator_`.\n",
      "\n",
      "base_estimator_ : DecisionTreeClassifier\n",
      "    The child estimator template used to create the collection of fitted\n",
      "    sub-estimators.\n",
      "\n",
      "    .. deprecated:: 1.2\n",
      "        `base_estimator_` is deprecated and will be removed in 1.4.\n",
      "        Use `estimator_` instead.\n",
      "\n",
      "estimators_ : list of DecisionTreeClassifier\n",
      "    The collection of fitted sub-estimators.\n",
      "\n",
      "classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      "    The classes labels (single output problem), or a list of arrays of\n",
      "    class labels (multi-output problem).\n",
      "\n",
      "n_classes_ : int or list\n",
      "    The number of classes (single output problem), or a list containing the\n",
      "    number of classes for each output (multi-output problem).\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_outputs_ : int\n",
      "    The number of outputs when ``fit`` is performed.\n",
      "\n",
      "feature_importances_ : ndarray of shape (n_features,)\n",
      "    The impurity-based feature importances.\n",
      "    The higher, the more important the feature.\n",
      "    The importance of a feature is computed as the (normalized)\n",
      "    total reduction of the criterion brought by that feature.  It is also\n",
      "    known as the Gini importance.\n",
      "\n",
      "    Warning: impurity-based feature importances can be misleading for\n",
      "    high cardinality features (many unique values). See\n",
      "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "oob_score_ : float\n",
      "    Score of the training dataset obtained using an out-of-bag estimate.\n",
      "    This attribute exists only when ``oob_score`` is True.\n",
      "\n",
      "oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
      "    Decision function computed with out-of-bag estimate on the training\n",
      "    set. If n_estimators is small it might be possible that a data point\n",
      "    was never left out during the bootstrap. In this case,\n",
      "    `oob_decision_function_` might contain NaN. This attribute exists\n",
      "    only when ``oob_score`` is True.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      "sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
      "    tree classifiers.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The default values for the parameters controlling the size of the trees\n",
      "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "unpruned trees which can potentially be very large on some data sets. To\n",
      "reduce memory consumption, the complexity and size of the trees should be\n",
      "controlled by setting those parameter values.\n",
      "\n",
      "The features are always randomly permuted at each split. Therefore,\n",
      "the best found split may vary, even with the same training data,\n",
      "``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      "of the criterion is identical for several splits enumerated during the\n",
      "search of the best split. To obtain a deterministic behaviour during\n",
      "fitting, ``random_state`` has to be fixed.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.ensemble import RandomForestClassifier\n",
      ">>> from sklearn.datasets import make_classification\n",
      ">>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      "...                            n_informative=2, n_redundant=0,\n",
      "...                            random_state=0, shuffle=False)\n",
      ">>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      ">>> clf.fit(X, y)\n",
      "RandomForestClassifier(...)\n",
      ">>> print(clf.predict([[0, 0, 0, 0]]))\n",
      "[1]\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\playdata\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986810551558753\n",
      "0.8086124401913876\n"
     ]
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train))\n",
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test))\n",
    "\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 5, 7, 9, 11],\n",
       "                         &#x27;min_samples_leaf&#x27;: [8, 12, 18],\n",
       "                         &#x27;min_samples_split&#x27;: [8, 16, 20],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 5, 7, 9, 11],\n",
       "                         &#x27;min_samples_leaf&#x27;: [8, 12, 18],\n",
       "                         &#x27;min_samples_split&#x27;: [8, 16, 20],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 400, 500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 5, 7, 9, 11],\n",
       "                         'min_samples_leaf': [8, 12, 18],\n",
       "                         'min_samples_split': [8, 16, 20],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV()를 활용한 최적의 파라미터 찾기\n",
    "params = {\n",
    "    'n_estimators' : [100, 200, 300, 400, 500], \n",
    "    'max_depth' : [3, 5, 7, 9, 11],\n",
    "    'min_samples_leaf' : [8, 12 ,18],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "grid = GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'min_samples_leaf': 8,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=11, min_samples_leaf=8, min_samples_split=8,\n",
       "                       n_estimators=300, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=11, min_samples_leaf=8, min_samples_split=8,\n",
       "                       n_estimators=300, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=11, min_samples_leaf=8, min_samples_split=8,\n",
       "                       n_estimators=300, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = grid.best_estimator_\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09079822, 0.02363469, 0.03678492, 0.15649737, 0.01882504,\n",
       "       0.06282865, 0.61063111])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_imp = pd.Series(data=best.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.barplot(x=f_imp.values, y=f_imp.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습] 와인데이터셋 랜덤포레스트 분류하기\n",
    "기본 모델 -> 튜닝 -> 점수 ->  특성 중요도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f3124b86b953d827ebe31858c9d7d57fd1033c1acdaf6cbd0987152aea75cb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
