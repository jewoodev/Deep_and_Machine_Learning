{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과적합, 분산 편향 트레이드오프, 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리 임포트\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사이킷런의 model_selection의 KFold()를 사용하는 경우(For loop 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 폴드를 분리할 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터를 준비하고 회귀 모형 객체를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "diab = load_diabetes()\n",
    "\n",
    "X = diab.data\n",
    "y = diab.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
       "         -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
       "         -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, -0.00567042, -0.04559945,\n",
       "         -0.03419447, -0.03235593, -0.00259226,  0.00286131, -0.02593034],\n",
       "        [-0.08906294, -0.04464164, -0.01159501, -0.03665608,  0.01219057,\n",
       "          0.02499059, -0.03603757,  0.03430886,  0.02268774, -0.00936191],\n",
       "        [ 0.00538306, -0.04464164, -0.03638469,  0.02187239,  0.00393485,\n",
       "          0.01559614,  0.00814208, -0.00259226, -0.03198764, -0.04664087]]),\n",
       " array([151.,  75., 141., 206., 135.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split()함수를 호출하여 폴드별로 분리될 행 인덱스 세트를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "         115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "         141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
       "         167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
       "         180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "         193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
       "         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
       "         232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "         245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257,\n",
       "         258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
       "         271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
       "         284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
       "         297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "         323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
       "         349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
       "         362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
       "         375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
       "         388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
       "         401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413,\n",
       "         414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "         427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "         440, 441]),\n",
       "  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "         51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "         68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "         85, 86, 87, 88])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88, 178, 179,\n",
       "         180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "         193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
       "         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
       "         232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "         245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257,\n",
       "         258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
       "         271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
       "         284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
       "         297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "         323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
       "         349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
       "         362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
       "         375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
       "         388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
       "         401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413,\n",
       "         414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "         427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "         440, 441]),\n",
       "  array([ 89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "         115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "         141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
       "         167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 266, 267, 268, 269,\n",
       "         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
       "         283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
       "         309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334,\n",
       "         335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347,\n",
       "         348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
       "         361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
       "         374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386,\n",
       "         387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399,\n",
       "         400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412,\n",
       "         413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
       "         426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438,\n",
       "         439, 440, 441]),\n",
       "  array([178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
       "         191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,\n",
       "         204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
       "         217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
       "         230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
       "         243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
       "         256, 257, 258, 259, 260, 261, 262, 263, 264, 265])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 354, 355, 356, 357, 358, 359, 360,\n",
       "         361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
       "         374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386,\n",
       "         387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399,\n",
       "         400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412,\n",
       "         413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
       "         426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438,\n",
       "         439, 440, 441]),\n",
       "  array([266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
       "         279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
       "         292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
       "         305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317,\n",
       "         318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
       "         331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343,\n",
       "         344, 345, 346, 347, 348, 349, 350, 351, 352, 353])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "         286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "         299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "         325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "         351, 352, 353]),\n",
       "  array([354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366,\n",
       "         367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "         380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "         393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
       "         419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
       "         432, 433, 434, 435, 436, 437, 438, 439, 440, 441]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kf.split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores = []\n",
    "lr = LinearRegression()\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx] # tuple unpacking\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    reg = lr.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4295561538258379,\n",
       " 0.5225993866099365,\n",
       " 0.4826805413452824,\n",
       " 0.42649776111040205,\n",
       " 0.5502483366517519]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores # 이 다섯개의 평균이 일반오차이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> R2 = 0.430\n",
      "2 -> R2 = 0.523\n",
      "3 -> R2 = 0.483\n",
      "4 -> R2 = 0.426\n",
      "5 -> R2 = 0.550\n",
      "average R2 = 0.482\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, r2 in enumerate(r2_scores):\n",
    "    print(i+1, f'-> R2 = {r2:.3f}')\n",
    "\n",
    "print(f'average R2 = {np.round(np.mean(r2_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 사이킷런의 cross_val_score 함수를 사용하여 K폴드 교차 검증 수행 without shuffling:\n",
    "- for loop 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42955615, 0.52259939, 0.48268054, 0.42649776, 0.55024834])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "diab = load_diabetes()\n",
    "X = diab.data\n",
    "y = diab.target\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "cross_val_score(lr, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.482"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(cross_val_score(lr, X, y, cv=5)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     kind  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "..    ...  \n",
       "145     2  \n",
       "146     2  \n",
       "147     2  \n",
       "148     2  \n",
       "149     2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "iris_df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "iris_df['kind'] = iris.target\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 사이킷런의 cross_val_score 함수를 사용하여 K폴드 교차 검증 수행 with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.489"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "diab = load_diabetes()\n",
    "X = diab.data\n",
    "y = diab.target\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=29) # stratify=True로 하면 같은 비율로 구성되게 shuffle 한다.\n",
    "lr = LinearRegression()\n",
    "\n",
    "np.round(np.mean(cross_val_score(lr, X, y, cv=kf)),3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제 - 보스턴 집값 데이터를 활용하여 다음 두 가지 과제를 수행하고 각각의  score 를 확인하세요.( 폴드 수 : 5, shuffle=False)\n",
    "\n",
    "1. KFold 객체를 활용하되  인덱스 집합을 리턴받아 학습을 수행하여 r2 값을 구하시오 ( 소숫점 이하 3자리)\n",
    "2. cross_val_score() 를 활용하여 r2값을 구하시오(소숫점 이하 세자리)\n",
    "\n",
    "R2: [ 0.639 0.714 0.587 0.079 -0.253] \n",
    "average R2: 0.353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_arff_parser',\n",
       " '_base',\n",
       " '_california_housing',\n",
       " '_covtype',\n",
       " '_kddcup99',\n",
       " '_lfw',\n",
       " '_olivetti_faces',\n",
       " '_openml',\n",
       " '_rcv1',\n",
       " '_samples_generator',\n",
       " '_species_distributions',\n",
       " '_svmlight_format_fast',\n",
       " '_svmlight_format_io',\n",
       " '_twenty_newsgroups',\n",
       " 'clear_data_home',\n",
       " 'dump_svmlight_file',\n",
       " 'fetch_20newsgroups',\n",
       " 'fetch_20newsgroups_vectorized',\n",
       " 'fetch_california_housing',\n",
       " 'fetch_covtype',\n",
       " 'fetch_kddcup99',\n",
       " 'fetch_lfw_pairs',\n",
       " 'fetch_lfw_people',\n",
       " 'fetch_olivetti_faces',\n",
       " 'fetch_openml',\n",
       " 'fetch_rcv1',\n",
       " 'fetch_species_distributions',\n",
       " 'get_data_home',\n",
       " 'load_breast_cancer',\n",
       " 'load_diabetes',\n",
       " 'load_digits',\n",
       " 'load_files',\n",
       " 'load_iris',\n",
       " 'load_linnerud',\n",
       " 'load_sample_image',\n",
       " 'load_sample_images',\n",
       " 'load_svmlight_file',\n",
       " 'load_svmlight_files',\n",
       " 'load_wine',\n",
       " 'make_biclusters',\n",
       " 'make_blobs',\n",
       " 'make_checkerboard',\n",
       " 'make_circles',\n",
       " 'make_classification',\n",
       " 'make_friedman1',\n",
       " 'make_friedman2',\n",
       " 'make_friedman3',\n",
       " 'make_gaussian_quantiles',\n",
       " 'make_hastie_10_2',\n",
       " 'make_low_rank_matrix',\n",
       " 'make_moons',\n",
       " 'make_multilabel_classification',\n",
       " 'make_regression',\n",
       " 'make_s_curve',\n",
       " 'make_sparse_coded_signal',\n",
       " 'make_sparse_spd_matrix',\n",
       " 'make_sparse_uncorrelated',\n",
       " 'make_spd_matrix',\n",
       " 'make_swiss_roll',\n",
       " 'textwrap']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "dir(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py:292: UserWarning: Multiple active versions of the dataset matching the name boston exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n",
      "c:\\Users\\PlayData\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "boston = fetch_openml('boston')\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      24.0\n",
       "1      21.6\n",
       "2      34.7\n",
       "3      33.4\n",
       "4      36.2\n",
       "       ... \n",
       "501    22.4\n",
       "502    20.6\n",
       "503    23.9\n",
       "504    22.0\n",
       "505    11.9\n",
       "Name: MEDV, Length: 506, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0   \n",
       "1    0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0   \n",
       "2    0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0   \n",
       "3    0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0   \n",
       "4    0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ..    ...   \n",
       "501  0.06263   0.0  11.93    0  0.573  6.593  69.1  2.4786   1  273.0   \n",
       "502  0.04527   0.0  11.93    0  0.573  6.120  76.7  2.2875   1  273.0   \n",
       "503  0.06076   0.0  11.93    0  0.573  6.976  91.0  2.1675   1  273.0   \n",
       "504  0.10959   0.0  11.93    0  0.573  6.794  89.3  2.3889   1  273.0   \n",
       "505  0.04741   0.0  11.93    0  0.573  6.030  80.8  2.5050   1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 인덱스 집합을 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 scores are [ 0.639  0.714  0.587  0.079 -0.253] and average r2 score is 0.353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "X = boston.data.values\n",
    "y = boston.target\n",
    "lr = LinearRegression()\n",
    "r2_scores = []\n",
    "\n",
    "kfold_object = KFold(n_splits=5, shuffle=False)\n",
    "for train_idx, test_idx in kfold_object.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "    \n",
    "    reg = lr.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "print(f'r2 scores are {np.round(r2_scores, 3)} and average r2 score is {np.round(np.mean(r2_scores),3)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. cross_val_score() 를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66875949, 0.7342547 , 0.70986601, 0.77595168, 0.68727731])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold_object = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_score(lr, X, y, cv=kfold_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(cross_val_score(lr, X, y, cv=kfold_object)),3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f3124b86b953d827ebe31858c9d7d57fd1033c1acdaf6cbd0987152aea75cb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
